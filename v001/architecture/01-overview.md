# 概要

## Overview
Podder.ai の アプリケーションは複数の独立したタスクと、パイプラインから構築されています。パイプラインはタスク間のデータの受け渡しや、実行順序、スケジューリングなどのオーケストレーションの役割を持っています。こちらがアプリケーションの全体像を示した図です。

![Architecture Overview](images/simple_architecture_overview.png)

### タスク
タスクは Podder.ai の最も重要な概念です。これは、アプリケーションの実行処理のステップの単位であり、単一のコンテナ上で実行されます。Podder CLI を使用して新しいタスクを追加することもできます。

### パイプライン
パイプラインはタスクの集合を定義したものです。タスク間のデータの受け渡しや、実行順序、スケジューリングなどのオーケストレーションの役割を持っています。パイプラインはユーザーが自由にカスタマイズすることが可能です。


## Principles
Podder.ai のアプリケーションは次のような基本方針で設計されています。
- 精度の最適化
- 自由なデプロイ

### 精度の最適化
#### パイプラインの柔軟性
複数のタスクを柔軟に組み合わせることを可能にし、`一連の処理による精度の最適化`を行います。タスクごとに精度を確認でき、どのタスクが全体の精度に影響を与えているか簡単に判別できます。また、問題のタスクだけを修正・更新できることで、他のタスクに影響を与えることなく一連の処理の予測精度の最適化を行うことができます。

![Pipeline Overview](images/pipeline_overview.png)

#### 業務やドメインに合わせたライブラリ
データバリデーションや、フォーマッター、オートコレクターなどの様々なライブラリを使用したタスクを追加することで、ドメインに合わせた AI ソリューションの提供が可能になります。これにより、`AIモデル単体ではなくトータルの精度向上`を行うことができます。

### 自由なデプロイ
オンプレミスや AWS、GCP などのプライベートクラウドといった、`あらゆる環境に対してアプリケーションをデプロイ`できるようにします。また、顧客のセキュリティ要件や既存システムに合わせた環境設計・構築ができることで、顧客ニーズに合わせたシステムインテグレーションを可能にします。

## Tech Stack
先ほど述べた基本方針を達成するために、Podder.ai では次の技術を採用しています。
- [Kubernetes](https://kubernetes.io/)
- [Docker](https://www.docker.com/)
- [Airflow](https://airflow.apache.org/)

![Tech Stack](images/tech_stack.png)


**Kubernetes** と **Docker** を利用することで次のことが可能になります。
- コンテナ型仮想化
- マイクロサービス基盤
- ポータブルな基盤構築

コンテナ型仮想化によって、あらゆる顧客環境でも同様にアプリケーションの導入・運用が可能になります。また、タスクごとにコンテナを分けて管理することで、`リソースの再利用`が可能になります。これにより負荷が集中しているタスクに対して、効率的にスケールアウトすることができ、コストを抑えることができます。さらに、問題がある特定のタスクだけ修正・更新ができ、安定したアプリケーションの運用を可能にします。


**Airflow** を使うことでタスクの実行順序やスケジューリングを管理できます。`タスクの並列実行や前タスクの結果による処理分岐も可能`で、顧客ニーズに合わせて必要なタスクを追加することで、AI 精度の最適化を行うことができます。
